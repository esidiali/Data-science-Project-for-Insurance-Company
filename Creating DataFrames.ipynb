{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1) ### display all the column s content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store csv files in a list, format : directory\\\\file.csv\n",
    "## read table that contains number of columns in dataframe by code nap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TAKE ALL PDF FROM A DIRECTORY\n",
    "csv_list = glob.glob('NAP_FILES_CSV/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store csv file in a list, format file.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNTION TO STORE PDFS IN A LIST\n",
    "def find_CSVs(directory):\n",
    "    files=[]\n",
    "    for i in range(0, len(directory)):\n",
    "        f= directory[i].rsplit('\\\\', 1)\n",
    "        files.append(f[1])\n",
    "    return files\n",
    "\n",
    "#print(\"Number of CSVs in depository: %s\" % len(find_CSVs(csv_list)))\n",
    "#print(\"First csv File: %s\" % find_CSVs(csv_list)[0])\n",
    "#print(\"First csv File name: %s\" % find_CSVs(csv_list)[0][0:26])\n",
    "#print(\"First csv File code nap: %s\" % str(find_CSVs(csv_list)[0][18:23]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### just to check how many columns we are dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv_stat(alist):\n",
    "    code_nap = []\n",
    "    length = []\n",
    "    #head_relevant_df_collection={}\n",
    "    for i in range(0, len(alist)):\n",
    "        #file = pd.read_csv('NAP_FILES_CSV/'+alist[i][0:26]+'.csv', encoding=\"utf-8\", index_col=False)\n",
    "        test_file = pd.read_csv('NAP_FILES_CSV/'+alist[i], encoding=\"utf-8\")\n",
    "\n",
    "            ## delete columns that contain most of NAN  values in the core table\n",
    "        core_relevant = test_file[14:95: ].dropna(thresh=len(test_file[14:95]) - 16, axis=1)\n",
    "        #core_relevant_df = file[14:95]\n",
    "        code_nap.append(alist[i][18:23])\n",
    "        length.append(len(core_relevant.columns))\n",
    "    lenght_stats_pdf=pd.DataFrame({'code': code_nap, 'length_pd': length})\n",
    "        \n",
    "    return lenght_stats_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=parse_csv_stat(find_CSVs(csv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.length_pd.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## now create data frames based on tests in notebooks 10 11 12 13 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframes(alist):\n",
    "    ## empty dataframes\n",
    "    head_frame = pd.DataFrame()\n",
    "    age_frame = pd.DataFrame()\n",
    "    sex_frame = pd.DataFrame()\n",
    "    qualif_pro_frame = pd.DataFrame()\n",
    "    nature_lesions_frame = pd.DataFrame()\n",
    "    siege_lesion_frame = pd.DataFrame()\n",
    "    lieu_frame = pd.DataFrame()\n",
    "    type_lieu_frame = pd.DataFrame()\n",
    "    deviation_frame = pd.DataFrame()\n",
    "    agent_deviation_frame = pd.DataFrame()\n",
    "    activite_phy_frame = pd.DataFrame()\n",
    "    modalites_blessure_frame = pd.DataFrame()\n",
    "    \n",
    "    ## empty lists of dataframes:\n",
    "    file_head = []\n",
    "    age_repartition_list = []\n",
    "    sex_repartition_list = []\n",
    "    qualif_pro_repartition_list = []\n",
    "    nature_lesions_repartition_list = []\n",
    "    siege_lesion_repartition_list = []\n",
    "    lieu_repartition_list = []\n",
    "    type_lieu_repartition_list = []\n",
    "    deviation_repartition_list = []\n",
    "    agent_deviation_repartition_list = []\n",
    "    activite_phy_repartition_list = []\n",
    "    modalites_blessure_repartition_list = []\n",
    "    \n",
    "    for i in range(0, len(alist)): ## ALIST = find_CSVs(csv_list)\n",
    "            code_value=alist[i][18:23]\n",
    "            ## read the csv file\n",
    "            test_file = pd.read_csv('NAP_FILES_CSV/'+alist[i], encoding=\"utf-8\")\n",
    "\n",
    "            ## delete columns that contain most of NAN  values in the core table\n",
    "            core_relevant = test_file[14:95: ].dropna(thresh=len(test_file[14:95]) - 16, axis=1)\n",
    "            ## creating the head of file (the same way for all files)\n",
    "            test_head = test_file.iloc[2:8,]\n",
    "            test_head = test_head.dropna(axis=1, how='all' )\n",
    "            test_head.columns = [\"index1\",\"valeur1\",\"index2\",\"valeur2\"]\n",
    "            test_head['index1'] = [\"Nombre de salariés\",\"Nombre d'accidents de travail en premier règlement\",\"dont avec au moins 4 jours d'arrêt\",\"Nombre de nouvelles incapacités permanentes\",\"Nombre de décès\",\"Nombre de journées perdues\"]\n",
    "            test_head['index2'] = [\"Indice de fréquence\",\"Taux de fréquence\",\"Taux de gravité\",\"Indice de gravité\",\"Nombre d'établissements\",\"0\"]\n",
    "            test_head = test_head.fillna(0)\n",
    "            #test_head.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            test_head['code']=code_value\n",
    "            cols = [test_head.columns[-1]] + test_head.columns[:-1].tolist()  # move last column to front\n",
    "            test_head = test_head[cols] \n",
    "            ## add the head to list\n",
    "            file_head.append(test_head)\n",
    "\n",
    "        \n",
    "            #age\n",
    "            age_repartition = core_relevant.iloc[0:10, 0:5]\n",
    "            #age_repartition = age_repartition.dropna(axis=1, how='all')\n",
    "            age_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            #age_repartition['index'] = age_repartition['index'].str[1:] ## removing each first digits in column s rows\n",
    "            #age_repartition.loc[23,'index']=\"65 ans et plus\"  #renaming the last row, because a zero is left by the command above(digit=)\n",
    "            age_repartition['index'] = [\"Non précisé\",\"Moins de 20 ans\",\"de 20 à 24 ans\",\"de 25 à 29 ans\", \"de 30 à 34 ans\",\n",
    "                            \"de 35 à 39 ans\",\"de 40 à 49 ans\",\"de 50 à 59 ans\",\"de 60 à 64 ans\", \"65 ans et plus\"]\n",
    "            #age_repartition.insert(loc=0, column='code', value=alist[i][18:23])  doesnt work dnt know why\n",
    "            age_repartition['code']=code_value\n",
    "            cols = [age_repartition.columns[-1]] + age_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            age_repartition = age_repartition[cols]\n",
    "            age_repartition_list.append(age_repartition)\n",
    "            \n",
    "\n",
    "            #sexe\n",
    "            sex_repartition = core_relevant.iloc[12:14, 0:5]\n",
    "            sex_repartition = sex_repartition.dropna(axis=1, how='all')\n",
    "            sex_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            sex_repartition['index'] = sex_repartition['index'].str.replace('\\d+', '')\n",
    "            #sex_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            sex_repartition['code']=code_value\n",
    "            cols = [sex_repartition.columns[-1]] + sex_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            sex_repartition = sex_repartition[cols]\n",
    "            sex_repartition_list.append(sex_repartition)\n",
    "\n",
    "\n",
    "            #qualification professionnelle\n",
    "            qualif_pro_repartition = core_relevant.iloc[16:25, 0:5]\n",
    "            qualif_pro_repartition = qualif_pro_repartition.dropna(axis=1, how='all')\n",
    "            qualif_pro_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            qualif_pro_repartition['index'] = qualif_pro_repartition['index'].str.replace('\\d+', '')\n",
    "            #qualif_pro_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            qualif_pro_repartition['code']=code_value\n",
    "            cols = [qualif_pro_repartition.columns[-1]] + qualif_pro_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            qualif_pro_repartition = qualif_pro_repartition[cols]\n",
    "            qualif_pro_repartition_list.append(qualif_pro_repartition)\n",
    "        \n",
    "\n",
    "            #nature de lesion\n",
    "            nature_lesions_repartition = core_relevant.iloc[27:63, 0:5]\n",
    "            nature_lesions_repartition = nature_lesions_repartition.dropna(axis=1, how='all')\n",
    "            nature_lesions_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            nature_lesions_repartition['index'] = nature_lesions_repartition['index'].str.replace('\\d+', '')\n",
    "            #nature_lesions_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            nature_lesions_repartition['code']=code_value\n",
    "            cols = [nature_lesions_repartition.columns[-1]] + nature_lesions_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            nature_lesions_repartition = nature_lesions_repartition[cols]\n",
    "            nature_lesions_repartition_list.append(nature_lesions_repartition)\n",
    "\n",
    "\n",
    "            # siège de lesion\n",
    "            siege_lesion_repartition = core_relevant.iloc[65:74, 0:5]\n",
    "            siege_lesion_repartition = siege_lesion_repartition.dropna(axis=1, how='all')\n",
    "            siege_lesion_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            siege_lesion_repartition['index'] = siege_lesion_repartition['index'].str.replace('\\d+', '')\n",
    "            #siege_lesion_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            siege_lesion_repartition['code']=code_value\n",
    "            cols = [siege_lesion_repartition.columns[-1]] + siege_lesion_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            siege_lesion_repartition = siege_lesion_repartition[cols]\n",
    "            siege_lesion_repartition_list.append(siege_lesion_repartition)\n",
    "\n",
    "\n",
    "\n",
    "            ## sub dataframes from right table\n",
    "            # lieu de travail\n",
    "            lieu_repartition = core_relevant.iloc[0:6, 5:]\n",
    "            lieu_repartition = lieu_repartition.dropna(axis=1, how='all')\n",
    "            lieu_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            lieu_repartition['index'] = lieu_repartition['index'].str.replace('\\d+', '')\n",
    "            #lieu_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            lieu_repartition['code']=code_value\n",
    "            cols = [lieu_repartition.columns[-1]] + lieu_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            lieu_repartition = lieu_repartition[cols]\n",
    "            lieu_repartition_list.append(lieu_repartition)\n",
    "\n",
    "\n",
    "            # type du lieu de travail\n",
    "            type_lieu_repartition = core_relevant.iloc[8:22, 5:]\n",
    "            type_lieu_repartition = type_lieu_repartition.dropna(axis=1, how='all')\n",
    "            type_lieu_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            type_lieu_repartition['index'] = type_lieu_repartition['index'].str.replace('\\d+', '')\n",
    "            #type_lieu_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            type_lieu_repartition['code']=code_value\n",
    "            cols = [type_lieu_repartition.columns[-1]] + type_lieu_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            type_lieu_repartition = type_lieu_repartition[cols]\n",
    "            type_lieu_repartition_list.append(type_lieu_repartition)\n",
    "\n",
    "            # Deviation\n",
    "            deviation_repartition = core_relevant.iloc[24:34, 5:]\n",
    "            deviation_repartition = deviation_repartition.dropna(axis=1, how='all')\n",
    "            deviation_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            deviation_repartition['index'] = deviation_repartition['index'].str.replace('\\d+', '')\n",
    "            #deviation_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            deviation_repartition['code']=code_value\n",
    "            cols = [deviation_repartition.columns[-1]] + deviation_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            deviation_repartition = deviation_repartition[cols]\n",
    "            deviation_repartition_list.append(deviation_repartition)\n",
    "\n",
    "            # Agent matériel de déviation\n",
    "            agent_deviation_repartition = core_relevant.iloc[36:58, 5:]\n",
    "            agent_deviation_repartition = agent_deviation_repartition.dropna(axis=1, how='all')\n",
    "            agent_deviation_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            agent_deviation_repartition['index'] = agent_deviation_repartition['index'].str.replace('\\d+', '')\n",
    "            #agent_deviation_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            agent_deviation_repartition['code']=code_value\n",
    "            cols = [agent_deviation_repartition.columns[-1]] + agent_deviation_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            agent_deviation_repartition = agent_deviation_repartition[cols]\n",
    "            agent_deviation_repartition_list.append(agent_deviation_repartition)\n",
    "\n",
    "            # Activité physique spécifique\n",
    "            activite_phy_repartition = core_relevant.iloc[60:69, 5:]\n",
    "            activite_phy_repartition = activite_phy_repartition.dropna(axis=1, how='all')\n",
    "            activite_phy_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            activite_phy_repartition['index'] = activite_phy_repartition['index'].str.replace('\\d+', '')\n",
    "            #activite_phy_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            activite_phy_repartition['code']=code_value\n",
    "            cols = [activite_phy_repartition.columns[-1]] + activite_phy_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            activite_phy_repartition = activite_phy_repartition[cols]\n",
    "            activite_phy_repartition_list.append(activite_phy_repartition)\n",
    "\n",
    "            #Modalités de blessure\n",
    "            modalites_blessure_repartition = core_relevant.iloc[71:81, 5:]\n",
    "            modalites_blessure_repartition = modalites_blessure_repartition.dropna(axis=1, how='all')\n",
    "            modalites_blessure_repartition.columns=[\"index\",\"nb_AT_1er_regle\",\"nb_new_IP\",\"nb_death\",\"nb_lost_days\"]\n",
    "            modalites_blessure_repartition['index'] = modalites_blessure_repartition['index'].str.replace('\\d+', '')\n",
    "            #modalites_blessure_repartition.insert(loc=0, column='code', value=alist[i][18:23])\n",
    "            modalites_blessure_repartition['code']=code_value\n",
    "            cols = [modalites_blessure_repartition.columns[-1]] + modalites_blessure_repartition.columns[:-1].tolist()  # move last column to front\n",
    "            modalites_blessure_repartition = modalites_blessure_repartition[cols]\n",
    "            modalites_blessure_repartition_list.append(modalites_blessure_repartition)\n",
    "            \n",
    "       \n",
    "    ### add frames to correspondant frame\n",
    "    \n",
    "    head_frame = pd.concat(file_head)\n",
    "    age_frame = pd.concat(age_repartition_list)\n",
    "    sex_frame = pd.concat(sex_repartition_list)\n",
    "    qualif_pro_frame = pd.concat(qualif_pro_repartition_list)\n",
    "    nature_lesions_frame = pd.concat(nature_lesions_repartition_list)\n",
    "    siege_lesion_frame = pd.concat(siege_lesion_repartition_list)\n",
    "    lieu_frame = pd.concat(lieu_repartition_list)\n",
    "    type_lieu_frame = pd.concat(type_lieu_repartition_list)\n",
    "    deviation_frame = pd.concat(deviation_repartition_list)\n",
    "    agent_deviation_frame = pd.concat(agent_deviation_repartition_list)\n",
    "    activite_phy_frame = pd.concat(activite_phy_repartition_list)\n",
    "    modalites_blessure_frame = pd.concat(modalites_blessure_repartition_list)\n",
    "    \n",
    "    head_frame.to_csv('Dataframes/files_head.csv', encoding='utf-8')\n",
    "    age_frame.to_csv('Dataframes/age_frame.csv', encoding='utf-8')\n",
    "    sex_frame.to_csv('Dataframes/sexe_frame.csv', encoding='utf-8')\n",
    "    qualif_pro_frame.to_csv('Dataframes/qualification_prof_frame.csv', encoding='utf-8')\n",
    "    nature_lesions_frame.to_csv('Dataframes/nature_lesions_frame.csv', encoding='utf-8')\n",
    "    siege_lesion_frame.to_csv('Dataframes/siege_lesion_frame.csv', encoding='utf-8')\n",
    "    lieu_frame.to_csv('Dataframes/lieu_accident_frame.csv', encoding='utf-8')\n",
    "    type_lieu_frame.to_csv('Dataframes/type_lieu_accident_frame.csv', encoding='utf-8')\n",
    "    deviation_frame.to_csv('Dataframes/deviation_frame.csv', encoding='utf-8')\n",
    "    agent_deviation_frame.to_csv('Dataframes/agent_deviation_frame.csv', encoding='utf-8')\n",
    "    activite_phy_frame.to_csv('Dataframes/activite_physique_frame.csv', encoding='utf-8')\n",
    "    modalites_blessure_frame.to_csv('Dataframes/modalites_blessure_frame.csv', encoding='utf-8')\n",
    "    \n",
    "    return head_frame, age_frame, sex_frame, qualif_pro_frame, nature_lesions_frame, siege_lesion_frame, lieu_frame, type_lieu_frame, deviation_frame, agent_deviation_frame, activite_phy_frame, modalites_blessure_frame\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_dataframes(find_CSVs(csv_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_frame=pd.read_csv('Dataframes/age_frame.csv', sep=',', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>index</th>\n",
       "      <th>nb_AT_1er_regle</th>\n",
       "      <th>nb_new_IP</th>\n",
       "      <th>nb_death</th>\n",
       "      <th>nb_lost_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>Non précisé</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>Moins de 20 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 20 à 24 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 25 à 29 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 30 à 34 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 35 à 39 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 40 à 49 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 50 à 59 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>de 60 à 64 ans</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0112Z</td>\n",
       "      <td>65 ans et plus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     code            index nb_AT_1er_regle  nb_new_IP  nb_death nb_lost_days\n",
       "14  0112Z      Non précisé               0          0         0            0\n",
       "15  0112Z  Moins de 20 ans               0          0         0            0\n",
       "16  0112Z   de 20 à 24 ans               0          0         0            0\n",
       "17  0112Z   de 25 à 29 ans               0          0         0            0\n",
       "18  0112Z   de 30 à 34 ans               0          0         0            0\n",
       "19  0112Z   de 35 à 39 ans               0          0         0            0\n",
       "20  0112Z   de 40 à 49 ans               0          0         0            0\n",
       "21  0112Z   de 50 à 59 ans               0          0         0            0\n",
       "22  0112Z   de 60 à 64 ans               0          0         0            0\n",
       "23  0112Z   65 ans et plus               0          0         0            0"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_frame[age_frame['code']=='0112Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
